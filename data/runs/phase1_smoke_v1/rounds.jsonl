{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 0, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 5, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.654190+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 1 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 0\n\n### Recent history (most recent last)\nNo history yet (this is the first round).\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 1, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 10, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.655189+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 2 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 5\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 2, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.655189+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 3 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 10\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 3, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 20, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.656196+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 4 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 15\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 4, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 25, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.656196+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 5 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 20\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 5, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.656196+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 6 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 25\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 6, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 35, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.657190+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 7 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 30\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 7, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 40, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.657190+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 8 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 35\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 8, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.657190+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 9 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 40\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 9, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 50, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.658191+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 10 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 45\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 10, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 55, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.658191+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 11 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 50\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 11, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 60, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.658191+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 12 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 55\n\n### Recent history (most recent last)\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 12, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 65, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.659191+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 13 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 60\n\n### Recent history (most recent last)\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 13, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 70, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.659191+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 14 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 65\n\n### Recent history (most recent last)\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 14, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 75, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.659191+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 15 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 70\n\n### Recent history (most recent last)\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 15, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 80, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.660191+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 16 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 75\n\n### Recent history (most recent last)\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 16, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 85, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.660816+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 17 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 80\n\n### Recent history (most recent last)\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 17, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 90, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.660816+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 18 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 85\n\n### Recent history (most recent last)\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 18, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 95, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.660816+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 19 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 90\n\n### Recent history (most recent last)\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 19, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 100, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.660816+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 20 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 95\n\n### Recent history (most recent last)\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 20, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 105, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.660816+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 21 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 100\n\n### Recent history (most recent last)\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 21, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 110, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.662331+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 22 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 105\n\n### Recent history (most recent last)\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 22, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 115, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.662920+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 23 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 110\n\n### Recent history (most recent last)\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 23, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 120, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.662920+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 24 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 115\n\n### Recent history (most recent last)\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 24, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 125, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.662920+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 25 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 120\n\n### Recent history (most recent last)\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 25, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 130, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.663927+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 26 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 125\n\n### Recent history (most recent last)\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 26, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 135, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.663927+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 27 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 130\n\n### Recent history (most recent last)\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 27, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 140, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.663927+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 28 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 135\n\n### Recent history (most recent last)\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 28, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 145, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.664925+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 29 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 140\n\n### Recent history (most recent last)\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 29, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 150, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.664925+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 30 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 145\n\n### Recent history (most recent last)\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 30, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 155, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.664925+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 31 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 150\n\n### Recent history (most recent last)\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 31, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 160, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.665925+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 32 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 155\n\n### Recent history (most recent last)\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 32, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 165, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.665925+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 33 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 160\n\n### Recent history (most recent last)\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 33, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 170, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.665925+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 34 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 165\n\n### Recent history (most recent last)\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 34, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 175, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.666926+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 35 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 170\n\n### Recent history (most recent last)\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 35, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 180, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.666926+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 36 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 175\n\n### Recent history (most recent last)\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 36, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 185, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.666926+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 37 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 180\n\n### Recent history (most recent last)\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 37, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 190, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.667925+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 38 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 185\n\n### Recent history (most recent last)\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 38, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 195, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.667925+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 39 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 190\n\n### Recent history (most recent last)\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 39, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 200, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.667925+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 40 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 195\n\n### Recent history (most recent last)\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 40, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 205, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.668926+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 41 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 200\n\n### Recent history (most recent last)\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 41, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 210, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.668926+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 42 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 205\n\n### Recent history (most recent last)\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 42, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 215, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.668926+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 43 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 210\n\n### Recent history (most recent last)\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 43, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 220, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.669926+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 44 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 215\n\n### Recent history (most recent last)\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 44, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 225, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.669926+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 45 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 220\n\n### Recent history (most recent last)\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 45, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 230, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.670926+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 46 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 225\n\n### Recent history (most recent last)\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 46, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 235, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.670926+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 47 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 230\n\n### Recent history (most recent last)\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 47, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 240, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.670926+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 48 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 235\n\n### Recent history (most recent last)\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 48, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 245, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.671925+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 49 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 240\n\n### Recent history (most recent last)\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 48: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 49, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 250, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.671925+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 50 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 245\n\n### Recent history (most recent last)\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 48: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 49: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 0, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 5, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.673925+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 1 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 0\n\n### Recent history (most recent last)\nNo history yet (this is the first round).\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 1, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 10, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.674926+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 2 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 5\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 2, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.674926+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 3 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 10\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 3, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 20, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.674926+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 4 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 15\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 4, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 25, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.674926+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 5 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 20\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 5, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.676432+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 6 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 25\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 6, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 35, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.677150+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 7 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 30\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 7, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 40, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.677150+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 8 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 35\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 8, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.677150+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 9 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 40\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 9, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 50, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.677150+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 10 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 45\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 10, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 55, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.677150+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 11 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 50\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 11, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 60, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.678672+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 12 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 55\n\n### Recent history (most recent last)\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 12, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 65, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.678672+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 13 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 60\n\n### Recent history (most recent last)\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 13, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 70, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.679678+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 14 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 65\n\n### Recent history (most recent last)\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 14, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 75, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.679678+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 15 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 70\n\n### Recent history (most recent last)\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 15, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 80, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.679678+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 16 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 75\n\n### Recent history (most recent last)\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 16, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 85, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.680679+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 17 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 80\n\n### Recent history (most recent last)\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 17, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 90, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.680679+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 18 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 85\n\n### Recent history (most recent last)\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 18, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 95, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.680679+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 19 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 90\n\n### Recent history (most recent last)\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 19, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 100, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.681679+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 20 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 95\n\n### Recent history (most recent last)\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 20, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 105, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.681679+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 21 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 100\n\n### Recent history (most recent last)\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 21, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 110, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.681679+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 22 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 105\n\n### Recent history (most recent last)\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 22, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 115, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.682679+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 23 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 110\n\n### Recent history (most recent last)\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 23, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 120, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.682679+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 24 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 115\n\n### Recent history (most recent last)\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 24, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 125, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.682679+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 25 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 120\n\n### Recent history (most recent last)\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 25, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 130, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.683678+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 26 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 125\n\n### Recent history (most recent last)\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 26, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 135, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.683678+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 27 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 130\n\n### Recent history (most recent last)\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 27, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 140, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.683678+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 28 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 135\n\n### Recent history (most recent last)\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 28, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 145, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.684678+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 29 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 140\n\n### Recent history (most recent last)\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 29, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 150, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.684678+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 30 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 145\n\n### Recent history (most recent last)\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 30, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 155, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.684678+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 31 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 150\n\n### Recent history (most recent last)\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 31, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 160, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.684678+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 32 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 155\n\n### Recent history (most recent last)\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 32, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 165, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.685678+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 33 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 160\n\n### Recent history (most recent last)\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 33, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 170, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.685678+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 34 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 165\n\n### Recent history (most recent last)\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 34, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 175, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.685678+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 35 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 170\n\n### Recent history (most recent last)\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 35, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 180, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.686683+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 36 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 175\n\n### Recent history (most recent last)\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 36, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 185, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.686683+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 37 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 180\n\n### Recent history (most recent last)\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 37, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 190, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.686683+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 38 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 185\n\n### Recent history (most recent last)\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 38, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 195, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.687683+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 39 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 190\n\n### Recent history (most recent last)\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 39, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 200, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.687683+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 40 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 195\n\n### Recent history (most recent last)\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 40, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 205, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.688683+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 41 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 200\n\n### Recent history (most recent last)\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 41, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 210, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.688683+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 42 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 205\n\n### Recent history (most recent last)\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 42, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 215, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.688683+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 43 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 210\n\n### Recent history (most recent last)\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 43, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 220, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.689683+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 44 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 215\n\n### Recent history (most recent last)\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 44, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 225, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.689683+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 45 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 220\n\n### Recent history (most recent last)\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 45, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 230, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.689683+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 46 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 225\n\n### Recent history (most recent last)\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 46, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 235, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.690684+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 47 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 230\n\n### Recent history (most recent last)\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 47, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 240, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.690684+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 48 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 235\n\n### Recent history (most recent last)\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 48, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 245, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.690684+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 49 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 240\n\n### Recent history (most recent last)\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 48: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 49, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 250, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.691684+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 50 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 245\n\n### Recent history (most recent last)\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 48: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 49: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 0, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 5, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.693479+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 1, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 1, "agent_b_cum_payoff": 6, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.693989+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 2, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 2, "agent_b_cum_payoff": 7, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.693989+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 3, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 3, "agent_b_cum_payoff": 8, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.694528+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 4, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 4, "agent_b_cum_payoff": 9, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.694528+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 5, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 5, "agent_b_cum_payoff": 10, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.695538+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 6, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 6, "agent_b_cum_payoff": 11, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.695538+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 7, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 7, "agent_b_cum_payoff": 12, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.695538+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 8, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 8, "agent_b_cum_payoff": 13, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.696550+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 9, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 9, "agent_b_cum_payoff": 14, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.696550+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 10, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 10, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.697555+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 11, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 11, "agent_b_cum_payoff": 16, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.697555+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 12, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 12, "agent_b_cum_payoff": 17, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.697555+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 13, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 13, "agent_b_cum_payoff": 18, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.698536+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 14, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 14, "agent_b_cum_payoff": 19, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.698536+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 15, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 15, "agent_b_cum_payoff": 20, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.699546+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 16, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 16, "agent_b_cum_payoff": 21, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.699546+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 17, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 17, "agent_b_cum_payoff": 22, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.699546+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 18, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 18, "agent_b_cum_payoff": 23, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.699546+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 19, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 19, "agent_b_cum_payoff": 24, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.700540+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 20, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 20, "agent_b_cum_payoff": 25, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.701066+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 21, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 21, "agent_b_cum_payoff": 26, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.701066+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 22, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 22, "agent_b_cum_payoff": 27, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.702073+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 23, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 23, "agent_b_cum_payoff": 28, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.702073+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 24, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 24, "agent_b_cum_payoff": 29, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.703072+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 25, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 25, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.703072+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 26, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 26, "agent_b_cum_payoff": 31, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.703072+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 27, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 27, "agent_b_cum_payoff": 32, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.704073+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 28, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 28, "agent_b_cum_payoff": 33, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.705073+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 29, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 29, "agent_b_cum_payoff": 34, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.705073+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 30, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 30, "agent_b_cum_payoff": 35, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.706086+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 31, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 31, "agent_b_cum_payoff": 36, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.706086+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 32, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 32, "agent_b_cum_payoff": 37, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.706086+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 33, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 33, "agent_b_cum_payoff": 38, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.707729+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 34, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 34, "agent_b_cum_payoff": 39, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.707729+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 35, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 35, "agent_b_cum_payoff": 40, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.708759+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 36, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 36, "agent_b_cum_payoff": 41, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.708759+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 37, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 37, "agent_b_cum_payoff": 42, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.709307+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 38, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 38, "agent_b_cum_payoff": 43, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.709307+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 39, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 39, "agent_b_cum_payoff": 44, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.709813+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 40, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 40, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.710398+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 41, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 41, "agent_b_cum_payoff": 46, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.710398+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 42, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 42, "agent_b_cum_payoff": 47, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.710398+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 43, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 43, "agent_b_cum_payoff": 48, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.710398+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 44, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 44, "agent_b_cum_payoff": 49, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.711405+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 45, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 45, "agent_b_cum_payoff": 50, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.711405+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 46, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 46, "agent_b_cum_payoff": 51, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.711405+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 47, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 47, "agent_b_cum_payoff": 52, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.712404+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 48, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 48, "agent_b_cum_payoff": 53, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.712404+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 49, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 49, "agent_b_cum_payoff": 54, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.712404+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 0, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 5, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.714405+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 1, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 1, "agent_b_cum_payoff": 6, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.714405+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 2, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 2, "agent_b_cum_payoff": 7, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.714405+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 3, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 3, "agent_b_cum_payoff": 8, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.715404+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 4, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 4, "agent_b_cum_payoff": 9, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.715404+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 5, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 5, "agent_b_cum_payoff": 10, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.715404+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 6, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 6, "agent_b_cum_payoff": 11, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.716412+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 7, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 7, "agent_b_cum_payoff": 12, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.716412+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 8, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 8, "agent_b_cum_payoff": 13, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.716412+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 9, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 9, "agent_b_cum_payoff": 14, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.716412+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 10, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 10, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.717411+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 11, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 11, "agent_b_cum_payoff": 16, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.717411+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 12, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 12, "agent_b_cum_payoff": 17, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.717411+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 13, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 13, "agent_b_cum_payoff": 18, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.718409+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 14, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 14, "agent_b_cum_payoff": 19, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.718409+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 15, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 15, "agent_b_cum_payoff": 20, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.718409+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 16, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 16, "agent_b_cum_payoff": 21, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.719410+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 17, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 17, "agent_b_cum_payoff": 22, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.719410+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 18, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 18, "agent_b_cum_payoff": 23, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.719410+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 19, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 19, "agent_b_cum_payoff": 24, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.720410+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 20, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 20, "agent_b_cum_payoff": 25, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.720410+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 21, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 21, "agent_b_cum_payoff": 26, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.721409+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 22, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 22, "agent_b_cum_payoff": 27, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.721409+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 23, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 23, "agent_b_cum_payoff": 28, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.721409+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 24, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 24, "agent_b_cum_payoff": 29, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.722410+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 25, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 25, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.723409+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 26, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 26, "agent_b_cum_payoff": 31, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.723409+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 27, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 27, "agent_b_cum_payoff": 32, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.723409+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 28, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 28, "agent_b_cum_payoff": 33, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.724411+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 29, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 29, "agent_b_cum_payoff": 34, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.724411+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 30, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 30, "agent_b_cum_payoff": 35, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.724411+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 31, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 31, "agent_b_cum_payoff": 36, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.725411+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 32, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 32, "agent_b_cum_payoff": 37, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.725411+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 33, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 33, "agent_b_cum_payoff": 38, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.725411+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 34, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 34, "agent_b_cum_payoff": 39, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.725411+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 35, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 35, "agent_b_cum_payoff": 40, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.726410+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 36, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 36, "agent_b_cum_payoff": 41, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.726410+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 37, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 37, "agent_b_cum_payoff": 42, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.726410+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 38, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 38, "agent_b_cum_payoff": 43, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.727410+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 39, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 39, "agent_b_cum_payoff": 44, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.727410+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 40, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 40, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.727410+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 41, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 41, "agent_b_cum_payoff": 46, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.728410+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 42, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 42, "agent_b_cum_payoff": 47, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.728410+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 43, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 43, "agent_b_cum_payoff": 48, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.728410+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 44, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 44, "agent_b_cum_payoff": 49, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.729411+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 45, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 45, "agent_b_cum_payoff": 50, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.729411+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 46, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 46, "agent_b_cum_payoff": 51, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.729411+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 47, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 47, "agent_b_cum_payoff": 52, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.729411+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 48, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 48, "agent_b_cum_payoff": 53, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.730411+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 49, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 49, "agent_b_cum_payoff": 54, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.730411+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 0, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 3, "agent_b_cum_payoff": 3, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.731781+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 1, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 6, "agent_b_cum_payoff": 6, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.731781+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 2, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 9, "agent_b_cum_payoff": 9, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.732780+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 3, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 12, "agent_b_cum_payoff": 12, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.732780+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 4, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 15, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.732780+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 5, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 18, "agent_b_cum_payoff": 18, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.732780+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 6, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 21, "agent_b_cum_payoff": 21, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.733781+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 7, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 24, "agent_b_cum_payoff": 24, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.733781+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 8, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 27, "agent_b_cum_payoff": 27, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.733781+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 9, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 30, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.733781+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 10, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 33, "agent_b_cum_payoff": 33, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.734780+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 11, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 36, "agent_b_cum_payoff": 36, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.734780+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 12, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 39, "agent_b_cum_payoff": 39, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.734780+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 13, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 42, "agent_b_cum_payoff": 42, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.735780+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 14, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 45, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.735780+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 15, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 48, "agent_b_cum_payoff": 48, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.735780+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 16, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 51, "agent_b_cum_payoff": 51, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.735780+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 17, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 54, "agent_b_cum_payoff": 54, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.736784+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 18, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 57, "agent_b_cum_payoff": 57, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.736784+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 19, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 60, "agent_b_cum_payoff": 60, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.736784+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 20, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 63, "agent_b_cum_payoff": 63, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.736784+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 21, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 66, "agent_b_cum_payoff": 66, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.737787+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 22, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 69, "agent_b_cum_payoff": 69, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.737787+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 23, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 72, "agent_b_cum_payoff": 72, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.738784+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 24, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 75, "agent_b_cum_payoff": 75, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.738784+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 25, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 78, "agent_b_cum_payoff": 78, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.738784+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 26, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 81, "agent_b_cum_payoff": 81, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.739785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 27, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 84, "agent_b_cum_payoff": 84, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.739785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 28, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 87, "agent_b_cum_payoff": 87, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.739785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 29, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 90, "agent_b_cum_payoff": 90, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.739785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 30, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 93, "agent_b_cum_payoff": 93, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.740785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 31, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 96, "agent_b_cum_payoff": 96, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.740785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 32, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 99, "agent_b_cum_payoff": 99, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.740785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 33, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 102, "agent_b_cum_payoff": 102, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.741784+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 34, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 105, "agent_b_cum_payoff": 105, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.741784+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 35, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 108, "agent_b_cum_payoff": 108, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.741784+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 36, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 111, "agent_b_cum_payoff": 111, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.741784+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 37, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 114, "agent_b_cum_payoff": 114, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.742785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 38, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 117, "agent_b_cum_payoff": 117, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.742785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 39, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 120, "agent_b_cum_payoff": 120, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.742785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 40, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 123, "agent_b_cum_payoff": 123, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.743785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 41, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 126, "agent_b_cum_payoff": 126, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.743785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 42, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 129, "agent_b_cum_payoff": 129, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.743785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 43, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 132, "agent_b_cum_payoff": 132, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.743785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 44, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 135, "agent_b_cum_payoff": 135, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.744785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 45, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 138, "agent_b_cum_payoff": 138, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.744785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 46, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 141, "agent_b_cum_payoff": 141, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.744785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 47, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 144, "agent_b_cum_payoff": 144, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.745785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 48, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 147, "agent_b_cum_payoff": 147, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.745785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 49, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 150, "agent_b_cum_payoff": 150, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.745785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 0, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 3, "agent_b_cum_payoff": 3, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.747783+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 1, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 6, "agent_b_cum_payoff": 6, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.747783+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 2, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 9, "agent_b_cum_payoff": 9, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.747783+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 3, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 12, "agent_b_cum_payoff": 12, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.748783+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 4, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 15, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.748783+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 5, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 18, "agent_b_cum_payoff": 18, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.748783+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 6, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 21, "agent_b_cum_payoff": 21, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.749783+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 7, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 24, "agent_b_cum_payoff": 24, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.749783+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 8, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 27, "agent_b_cum_payoff": 27, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.749783+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 9, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 30, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.750784+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 10, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 33, "agent_b_cum_payoff": 33, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.750784+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 11, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 36, "agent_b_cum_payoff": 36, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.751287+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 12, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 39, "agent_b_cum_payoff": 39, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.751287+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 13, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 42, "agent_b_cum_payoff": 42, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.751287+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 14, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 45, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.751287+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 15, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 48, "agent_b_cum_payoff": 48, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.752292+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 16, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 51, "agent_b_cum_payoff": 51, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.752292+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 17, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 54, "agent_b_cum_payoff": 54, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.752292+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 18, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 57, "agent_b_cum_payoff": 57, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.752292+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 19, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 60, "agent_b_cum_payoff": 60, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.753291+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 20, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 63, "agent_b_cum_payoff": 63, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.754026+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 21, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 66, "agent_b_cum_payoff": 66, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.754026+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 22, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 69, "agent_b_cum_payoff": 69, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.755034+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 23, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 72, "agent_b_cum_payoff": 72, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.755034+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 24, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 75, "agent_b_cum_payoff": 75, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.755412+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 25, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 78, "agent_b_cum_payoff": 78, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.755917+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 26, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 81, "agent_b_cum_payoff": 81, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.755917+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 27, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 84, "agent_b_cum_payoff": 84, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.756443+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 28, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 87, "agent_b_cum_payoff": 87, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.756443+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 29, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 90, "agent_b_cum_payoff": 90, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.757449+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 30, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 93, "agent_b_cum_payoff": 93, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.757449+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 31, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 96, "agent_b_cum_payoff": 96, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.757449+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 32, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 99, "agent_b_cum_payoff": 99, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.757449+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 33, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 102, "agent_b_cum_payoff": 102, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.758450+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 34, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 105, "agent_b_cum_payoff": 105, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.758450+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 35, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 108, "agent_b_cum_payoff": 108, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.758450+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 36, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 111, "agent_b_cum_payoff": 111, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.759449+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 37, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 114, "agent_b_cum_payoff": 114, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.759449+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 38, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 117, "agent_b_cum_payoff": 117, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.759449+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 39, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 120, "agent_b_cum_payoff": 120, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.760449+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 40, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 123, "agent_b_cum_payoff": 123, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.760449+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 41, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 126, "agent_b_cum_payoff": 126, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.760449+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 42, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 129, "agent_b_cum_payoff": 129, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.760449+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 43, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 132, "agent_b_cum_payoff": 132, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.761448+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 44, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 135, "agent_b_cum_payoff": 135, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.761448+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 45, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 138, "agent_b_cum_payoff": 138, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.761448+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 46, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 141, "agent_b_cum_payoff": 141, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.762449+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 47, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 144, "agent_b_cum_payoff": 144, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.762449+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 48, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 147, "agent_b_cum_payoff": 147, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.762449+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 49, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 150, "agent_b_cum_payoff": 150, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T09:59:45.762449+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 0, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 5, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.787806+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 1 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 0\n\n### Recent history (most recent last)\nNo history yet (this is the first round).\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 1, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 10, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.788806+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 2 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 5\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 2, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.788806+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 3 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 10\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 3, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 20, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.788806+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 4 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 15\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 4, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 25, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.789807+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 5 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 20\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 5, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.789807+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 6 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 25\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 6, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 35, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.789807+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 7 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 30\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 7, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 40, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.790807+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 8 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 35\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 8, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.790807+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 9 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 40\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 9, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 50, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.790807+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 10 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 45\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 10, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 55, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.791807+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 11 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 50\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 11, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 60, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.791807+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 12 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 55\n\n### Recent history (most recent last)\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 12, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 65, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.791807+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 13 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 60\n\n### Recent history (most recent last)\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 13, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 70, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.792807+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 14 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 65\n\n### Recent history (most recent last)\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 14, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 75, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.792807+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 15 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 70\n\n### Recent history (most recent last)\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 15, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 80, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.792807+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 16 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 75\n\n### Recent history (most recent last)\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 16, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 85, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.793812+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 17 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 80\n\n### Recent history (most recent last)\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 17, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 90, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.793812+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 18 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 85\n\n### Recent history (most recent last)\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 18, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 95, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.793812+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 19 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 90\n\n### Recent history (most recent last)\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 19, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 100, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.794811+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 20 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 95\n\n### Recent history (most recent last)\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 20, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 105, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.794811+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 21 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 100\n\n### Recent history (most recent last)\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 21, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 110, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.794811+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 22 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 105\n\n### Recent history (most recent last)\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 22, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 115, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.795811+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 23 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 110\n\n### Recent history (most recent last)\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 23, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 120, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.795811+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 24 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 115\n\n### Recent history (most recent last)\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 24, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 125, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.795811+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 25 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 120\n\n### Recent history (most recent last)\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 25, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 130, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.795811+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 26 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 125\n\n### Recent history (most recent last)\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 26, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 135, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.796812+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 27 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 130\n\n### Recent history (most recent last)\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 27, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 140, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.796812+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 28 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 135\n\n### Recent history (most recent last)\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 28, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 145, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.796812+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 29 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 140\n\n### Recent history (most recent last)\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 29, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 150, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.797812+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 30 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 145\n\n### Recent history (most recent last)\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 30, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 155, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.797812+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 31 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 150\n\n### Recent history (most recent last)\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 31, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 160, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.797812+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 32 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 155\n\n### Recent history (most recent last)\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 32, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 165, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.798812+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 33 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 160\n\n### Recent history (most recent last)\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 33, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 170, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.798812+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 34 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 165\n\n### Recent history (most recent last)\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 34, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 175, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.799811+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 35 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 170\n\n### Recent history (most recent last)\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 35, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 180, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.799811+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 36 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 175\n\n### Recent history (most recent last)\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 36, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 185, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.800702+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 37 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 180\n\n### Recent history (most recent last)\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 37, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 190, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.801208+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 38 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 185\n\n### Recent history (most recent last)\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 38, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 195, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.801208+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 39 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 190\n\n### Recent history (most recent last)\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 39, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 200, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.801208+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 40 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 195\n\n### Recent history (most recent last)\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 40, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 205, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.802215+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 41 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 200\n\n### Recent history (most recent last)\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 41, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 210, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.802215+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 42 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 205\n\n### Recent history (most recent last)\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 42, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 215, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.802215+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 43 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 210\n\n### Recent history (most recent last)\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 43, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 220, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.803214+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 44 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 215\n\n### Recent history (most recent last)\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 44, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 225, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.803214+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 45 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 220\n\n### Recent history (most recent last)\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 45, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 230, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.803214+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 46 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 225\n\n### Recent history (most recent last)\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 46, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 235, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.804215+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 47 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 230\n\n### Recent history (most recent last)\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 47, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 240, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.804215+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 48 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 235\n\n### Recent history (most recent last)\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 48, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 245, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.804215+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 49 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 240\n\n### Recent history (most recent last)\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 48: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 49, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 250, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.804215+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 50 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 245\n\n### Recent history (most recent last)\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 48: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 49: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 0, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 5, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.807214+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 1 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 0\n\n### Recent history (most recent last)\nNo history yet (this is the first round).\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 1, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 10, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.808214+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 2 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 5\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 2, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.808214+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 3 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 10\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 3, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 20, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.808214+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 4 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 15\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 4, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 25, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.808214+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 5 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 20\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 5, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.809479+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 6 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 25\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 6, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 35, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.809479+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 7 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 30\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 7, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 40, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.809479+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 8 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 35\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 8, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.810480+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 9 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 40\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 9, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 50, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.810480+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 10 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 45\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 10, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 55, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.810480+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 11 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 50\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 11, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 60, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.811480+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 12 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 55\n\n### Recent history (most recent last)\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 12, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 65, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.811480+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 13 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 60\n\n### Recent history (most recent last)\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 13, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 70, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.811480+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 14 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 65\n\n### Recent history (most recent last)\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 14, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 75, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.812479+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 15 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 70\n\n### Recent history (most recent last)\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 15, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 80, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.812479+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 16 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 75\n\n### Recent history (most recent last)\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 16, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 85, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.812479+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 17 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 80\n\n### Recent history (most recent last)\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 17, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 90, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.813479+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 18 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 85\n\n### Recent history (most recent last)\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 18, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 95, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.813479+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 19 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 90\n\n### Recent history (most recent last)\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 19, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 100, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.813479+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 20 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 95\n\n### Recent history (most recent last)\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 20, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 105, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.814479+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 21 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 100\n\n### Recent history (most recent last)\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 21, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 110, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.815055+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 22 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 105\n\n### Recent history (most recent last)\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 22, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 115, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.815055+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 23 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 110\n\n### Recent history (most recent last)\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 23, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 120, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.815055+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 24 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 115\n\n### Recent history (most recent last)\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 24, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 125, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.816061+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 25 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 120\n\n### Recent history (most recent last)\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 25, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 130, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.816061+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 26 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 125\n\n### Recent history (most recent last)\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 26, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 135, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.816061+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 27 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 130\n\n### Recent history (most recent last)\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 27, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 140, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.817061+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 28 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 135\n\n### Recent history (most recent last)\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 28, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 145, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.817061+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 29 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 140\n\n### Recent history (most recent last)\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 29, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 150, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.817061+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 30 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 145\n\n### Recent history (most recent last)\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 30, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 155, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.818060+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 31 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 150\n\n### Recent history (most recent last)\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 31, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 160, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.818060+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 32 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 155\n\n### Recent history (most recent last)\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 32, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 165, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.818060+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 33 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 160\n\n### Recent history (most recent last)\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 33, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 170, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.819062+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 34 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 165\n\n### Recent history (most recent last)\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 34, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 175, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.819062+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 35 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 170\n\n### Recent history (most recent last)\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 35, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 180, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.819062+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 36 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 175\n\n### Recent history (most recent last)\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 36, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 185, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.820067+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 37 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 180\n\n### Recent history (most recent last)\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 37, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 190, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.820067+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 38 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 185\n\n### Recent history (most recent last)\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 38, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 195, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.820067+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 39 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 190\n\n### Recent history (most recent last)\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 39, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 200, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.821067+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 40 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 195\n\n### Recent history (most recent last)\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 40, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 205, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.821067+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 41 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 200\n\n### Recent history (most recent last)\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 41, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 210, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.821067+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 42 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 205\n\n### Recent history (most recent last)\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 42, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 215, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.822068+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 43 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 210\n\n### Recent history (most recent last)\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 43, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 220, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.822068+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 44 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 215\n\n### Recent history (most recent last)\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 44, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 225, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.822068+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 45 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 220\n\n### Recent history (most recent last)\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 45, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 230, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.823066+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 46 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 225\n\n### Recent history (most recent last)\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 46, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 235, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.823066+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 47 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 230\n\n### Recent history (most recent last)\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 47, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 240, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.823066+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 48 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 235\n\n### Recent history (most recent last)\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 48, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 245, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.824066+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 49 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 240\n\n### Recent history (most recent last)\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 48: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 49, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 250, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.824066+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 50 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 245\n\n### Recent history (most recent last)\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 48: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 49: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 0, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 5, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.826066+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 1, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 1, "agent_b_cum_payoff": 6, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.826066+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 2, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 2, "agent_b_cum_payoff": 7, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.826066+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 3, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 3, "agent_b_cum_payoff": 8, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.826066+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 4, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 4, "agent_b_cum_payoff": 9, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.827068+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 5, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 5, "agent_b_cum_payoff": 10, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.827068+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 6, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 6, "agent_b_cum_payoff": 11, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.827068+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 7, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 7, "agent_b_cum_payoff": 12, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.828067+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 8, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 8, "agent_b_cum_payoff": 13, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.828067+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 9, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 9, "agent_b_cum_payoff": 14, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.828067+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 10, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 10, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.828067+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 11, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 11, "agent_b_cum_payoff": 16, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.829067+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 12, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 12, "agent_b_cum_payoff": 17, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.829067+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 13, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 13, "agent_b_cum_payoff": 18, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.829067+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 14, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 14, "agent_b_cum_payoff": 19, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.829067+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 15, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 15, "agent_b_cum_payoff": 20, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.830067+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 16, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 16, "agent_b_cum_payoff": 21, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.831067+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 17, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 17, "agent_b_cum_payoff": 22, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.832066+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 18, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 18, "agent_b_cum_payoff": 23, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.832066+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 19, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 19, "agent_b_cum_payoff": 24, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.833067+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 20, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 20, "agent_b_cum_payoff": 25, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.833067+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 21, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 21, "agent_b_cum_payoff": 26, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.833067+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 22, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 22, "agent_b_cum_payoff": 27, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.833067+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 23, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 23, "agent_b_cum_payoff": 28, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.833067+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 24, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 24, "agent_b_cum_payoff": 29, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.833067+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 25, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 25, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.834574+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 26, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 26, "agent_b_cum_payoff": 31, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.834574+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 27, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 27, "agent_b_cum_payoff": 32, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.834574+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 28, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 28, "agent_b_cum_payoff": 33, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.835581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 29, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 29, "agent_b_cum_payoff": 34, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.835581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 30, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 30, "agent_b_cum_payoff": 35, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.835581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 31, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 31, "agent_b_cum_payoff": 36, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.835581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 32, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 32, "agent_b_cum_payoff": 37, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.836583+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 33, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 33, "agent_b_cum_payoff": 38, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.836583+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 34, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 34, "agent_b_cum_payoff": 39, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.836583+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 35, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 35, "agent_b_cum_payoff": 40, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.837581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 36, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 36, "agent_b_cum_payoff": 41, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.837581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 37, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 37, "agent_b_cum_payoff": 42, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.837581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 38, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 38, "agent_b_cum_payoff": 43, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.837581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 39, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 39, "agent_b_cum_payoff": 44, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.838581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 40, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 40, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.838581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 41, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 41, "agent_b_cum_payoff": 46, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.838581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 42, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 42, "agent_b_cum_payoff": 47, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.838581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 43, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 43, "agent_b_cum_payoff": 48, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.839581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 44, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 44, "agent_b_cum_payoff": 49, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.839581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 45, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 45, "agent_b_cum_payoff": 50, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.839581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 46, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 46, "agent_b_cum_payoff": 51, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.839581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 47, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 47, "agent_b_cum_payoff": 52, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.840581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 48, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 48, "agent_b_cum_payoff": 53, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.840581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 49, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 49, "agent_b_cum_payoff": 54, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.840581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 0, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 5, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.842581+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 1, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 1, "agent_b_cum_payoff": 6, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.843086+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 2, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 2, "agent_b_cum_payoff": 7, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.843086+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 3, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 3, "agent_b_cum_payoff": 8, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.843632+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 4, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 4, "agent_b_cum_payoff": 9, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.843632+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 5, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 5, "agent_b_cum_payoff": 10, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.843632+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 6, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 6, "agent_b_cum_payoff": 11, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.843632+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 7, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 7, "agent_b_cum_payoff": 12, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.844638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 8, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 8, "agent_b_cum_payoff": 13, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.844638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 9, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 9, "agent_b_cum_payoff": 14, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.844638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 10, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 10, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.844638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 11, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 11, "agent_b_cum_payoff": 16, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.845638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 12, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 12, "agent_b_cum_payoff": 17, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.845638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 13, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 13, "agent_b_cum_payoff": 18, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.846638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 14, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 14, "agent_b_cum_payoff": 19, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.846638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 15, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 15, "agent_b_cum_payoff": 20, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.846638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 16, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 16, "agent_b_cum_payoff": 21, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.847638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 17, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 17, "agent_b_cum_payoff": 22, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.847638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 18, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 18, "agent_b_cum_payoff": 23, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.847638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 19, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 19, "agent_b_cum_payoff": 24, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.847638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 20, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 20, "agent_b_cum_payoff": 25, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.848637+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 21, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 21, "agent_b_cum_payoff": 26, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.848637+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 22, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 22, "agent_b_cum_payoff": 27, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.848637+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 23, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 23, "agent_b_cum_payoff": 28, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.848637+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 24, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 24, "agent_b_cum_payoff": 29, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.849638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 25, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 25, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.849638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 26, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 26, "agent_b_cum_payoff": 31, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.849638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 27, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 27, "agent_b_cum_payoff": 32, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.850637+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 28, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 28, "agent_b_cum_payoff": 33, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.850637+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 29, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 29, "agent_b_cum_payoff": 34, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.850637+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 30, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 30, "agent_b_cum_payoff": 35, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.850637+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 31, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 31, "agent_b_cum_payoff": 36, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.851639+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 32, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 32, "agent_b_cum_payoff": 37, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.851639+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 33, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 33, "agent_b_cum_payoff": 38, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.851639+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 34, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 34, "agent_b_cum_payoff": 39, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.852638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 35, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 35, "agent_b_cum_payoff": 40, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.852638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 36, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 36, "agent_b_cum_payoff": 41, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.852638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 37, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 37, "agent_b_cum_payoff": 42, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.852638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 38, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 38, "agent_b_cum_payoff": 43, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.853637+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 39, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 39, "agent_b_cum_payoff": 44, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.853637+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 40, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 40, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.853637+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 41, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 41, "agent_b_cum_payoff": 46, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.853637+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 42, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 42, "agent_b_cum_payoff": 47, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.854638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 43, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 43, "agent_b_cum_payoff": 48, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.854638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 44, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 44, "agent_b_cum_payoff": 49, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.854638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 45, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 45, "agent_b_cum_payoff": 50, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.855638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 46, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 46, "agent_b_cum_payoff": 51, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.855638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 47, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 47, "agent_b_cum_payoff": 52, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.855638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 48, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 48, "agent_b_cum_payoff": 53, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.855638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 49, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 49, "agent_b_cum_payoff": 54, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.855638+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 0, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 3, "agent_b_cum_payoff": 3, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.856637+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 1, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 6, "agent_b_cum_payoff": 6, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.858142+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 2, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 9, "agent_b_cum_payoff": 9, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.858142+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 3, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 12, "agent_b_cum_payoff": 12, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.858142+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 4, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 15, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.858142+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 5, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 18, "agent_b_cum_payoff": 18, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.859147+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 6, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 21, "agent_b_cum_payoff": 21, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.859147+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 7, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 24, "agent_b_cum_payoff": 24, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.859147+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 8, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 27, "agent_b_cum_payoff": 27, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.860147+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 9, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 30, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.860147+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 10, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 33, "agent_b_cum_payoff": 33, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.860147+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 11, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 36, "agent_b_cum_payoff": 36, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.860147+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 12, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 39, "agent_b_cum_payoff": 39, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.861147+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 13, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 42, "agent_b_cum_payoff": 42, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.861548+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 14, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 45, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.862052+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 15, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 48, "agent_b_cum_payoff": 48, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.862052+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 16, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 51, "agent_b_cum_payoff": 51, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.862539+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 17, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 54, "agent_b_cum_payoff": 54, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.862539+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 18, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 57, "agent_b_cum_payoff": 57, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.863045+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 19, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 60, "agent_b_cum_payoff": 60, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.863045+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 20, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 63, "agent_b_cum_payoff": 63, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.863776+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 21, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 66, "agent_b_cum_payoff": 66, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.863776+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 22, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 69, "agent_b_cum_payoff": 69, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.863776+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 23, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 72, "agent_b_cum_payoff": 72, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.863776+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 24, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 75, "agent_b_cum_payoff": 75, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.864782+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 25, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 78, "agent_b_cum_payoff": 78, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.864782+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 26, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 81, "agent_b_cum_payoff": 81, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.864782+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 27, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 84, "agent_b_cum_payoff": 84, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.864782+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 28, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 87, "agent_b_cum_payoff": 87, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.865785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 29, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 90, "agent_b_cum_payoff": 90, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.865785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 30, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 93, "agent_b_cum_payoff": 93, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.865785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 31, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 96, "agent_b_cum_payoff": 96, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.865785+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 32, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 99, "agent_b_cum_payoff": 99, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.866781+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 33, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 102, "agent_b_cum_payoff": 102, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.866781+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 34, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 105, "agent_b_cum_payoff": 105, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.866781+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 35, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 108, "agent_b_cum_payoff": 108, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.867784+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 36, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 111, "agent_b_cum_payoff": 111, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.867784+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 37, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 114, "agent_b_cum_payoff": 114, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.867784+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 38, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 117, "agent_b_cum_payoff": 117, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.867784+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 39, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 120, "agent_b_cum_payoff": 120, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.868782+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 40, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 123, "agent_b_cum_payoff": 123, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.868782+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 41, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 126, "agent_b_cum_payoff": 126, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.868782+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 42, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 129, "agent_b_cum_payoff": 129, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.868782+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 43, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 132, "agent_b_cum_payoff": 132, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.869782+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 44, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 135, "agent_b_cum_payoff": 135, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.869782+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 45, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 138, "agent_b_cum_payoff": 138, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.869782+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 46, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 141, "agent_b_cum_payoff": 141, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.869782+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 47, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 144, "agent_b_cum_payoff": 144, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.869782+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 48, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 147, "agent_b_cum_payoff": 147, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.869782+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 49, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 150, "agent_b_cum_payoff": 150, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.871287+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 0, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 3, "agent_b_cum_payoff": 3, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.872294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 1, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 6, "agent_b_cum_payoff": 6, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.872294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 2, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 9, "agent_b_cum_payoff": 9, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.873294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 3, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 12, "agent_b_cum_payoff": 12, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.873294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 4, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 15, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.873294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 5, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 18, "agent_b_cum_payoff": 18, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.873294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 6, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 21, "agent_b_cum_payoff": 21, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.874294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 7, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 24, "agent_b_cum_payoff": 24, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.874294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 8, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 27, "agent_b_cum_payoff": 27, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.874294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 9, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 30, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.875293+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 10, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 33, "agent_b_cum_payoff": 33, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.875293+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 11, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 36, "agent_b_cum_payoff": 36, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.875293+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 12, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 39, "agent_b_cum_payoff": 39, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.875293+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 13, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 42, "agent_b_cum_payoff": 42, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.876294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 14, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 45, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.876294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 15, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 48, "agent_b_cum_payoff": 48, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.877295+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 16, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 51, "agent_b_cum_payoff": 51, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.877295+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 17, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 54, "agent_b_cum_payoff": 54, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.877295+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 18, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 57, "agent_b_cum_payoff": 57, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.877295+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 19, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 60, "agent_b_cum_payoff": 60, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.878294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 20, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 63, "agent_b_cum_payoff": 63, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.878294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 21, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 66, "agent_b_cum_payoff": 66, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.878294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 22, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 69, "agent_b_cum_payoff": 69, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.878294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 23, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 72, "agent_b_cum_payoff": 72, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.879294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 24, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 75, "agent_b_cum_payoff": 75, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.879294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 25, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 78, "agent_b_cum_payoff": 78, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.879294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 26, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 81, "agent_b_cum_payoff": 81, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.879294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 27, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 84, "agent_b_cum_payoff": 84, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.880294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 28, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 87, "agent_b_cum_payoff": 87, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.880294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 29, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 90, "agent_b_cum_payoff": 90, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.880294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 30, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 93, "agent_b_cum_payoff": 93, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.880294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 31, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 96, "agent_b_cum_payoff": 96, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.881294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 32, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 99, "agent_b_cum_payoff": 99, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.881294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 33, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 102, "agent_b_cum_payoff": 102, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.881294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 34, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 105, "agent_b_cum_payoff": 105, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.882294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 35, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 108, "agent_b_cum_payoff": 108, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.882294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 36, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 111, "agent_b_cum_payoff": 111, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.882294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 37, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 114, "agent_b_cum_payoff": 114, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.882294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 38, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 117, "agent_b_cum_payoff": 117, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.883294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 39, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 120, "agent_b_cum_payoff": 120, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.883294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 40, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 123, "agent_b_cum_payoff": 123, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.883294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 41, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 126, "agent_b_cum_payoff": 126, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.883294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 42, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 129, "agent_b_cum_payoff": 129, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.884294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 43, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 132, "agent_b_cum_payoff": 132, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.884294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 44, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 135, "agent_b_cum_payoff": 135, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.884294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 45, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 138, "agent_b_cum_payoff": 138, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.884294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 46, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 141, "agent_b_cum_payoff": 141, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.885294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 47, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 144, "agent_b_cum_payoff": 144, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.885294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 48, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 147, "agent_b_cum_payoff": 147, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.885294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 49, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 150, "agent_b_cum_payoff": 150, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-26T10:06:46.886294+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 0, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 5, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.170556+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 1 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 0\n\n### Recent history (most recent last)\nNo history yet (this is the first round).\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 1, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 10, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.171556+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 2 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 5\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 2, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.171556+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 3 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 10\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 3, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 20, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.171556+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 4 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 15\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 4, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 25, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.172556+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 5 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 20\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 5, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.172556+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 6 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 25\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 6, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 35, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.172556+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 7 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 30\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 7, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 40, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.172556+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 8 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 35\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 8, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.173556+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 9 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 40\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 9, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 50, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.173556+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 10 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 45\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 10, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 55, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.173556+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 11 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 50\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 11, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 60, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.174556+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 12 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 55\n\n### Recent history (most recent last)\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 12, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 65, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.174556+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 13 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 60\n\n### Recent history (most recent last)\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 13, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 70, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.175557+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 14 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 65\n\n### Recent history (most recent last)\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 14, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 75, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.175557+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 15 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 70\n\n### Recent history (most recent last)\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 15, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 80, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.176246+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 16 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 75\n\n### Recent history (most recent last)\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 16, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 85, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.176246+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 17 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 80\n\n### Recent history (most recent last)\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 17, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 90, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.176246+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 18 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 85\n\n### Recent history (most recent last)\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 18, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 95, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.177252+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 19 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 90\n\n### Recent history (most recent last)\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 19, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 100, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.177252+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 20 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 95\n\n### Recent history (most recent last)\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 20, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 105, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.177252+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 21 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 100\n\n### Recent history (most recent last)\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 21, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 110, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.178252+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 22 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 105\n\n### Recent history (most recent last)\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 22, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 115, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.178252+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 23 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 110\n\n### Recent history (most recent last)\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 23, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 120, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.178252+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 24 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 115\n\n### Recent history (most recent last)\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 24, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 125, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.179257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 25 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 120\n\n### Recent history (most recent last)\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 25, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 130, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.179257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 26 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 125\n\n### Recent history (most recent last)\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 26, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 135, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.179257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 27 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 130\n\n### Recent history (most recent last)\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 27, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 140, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.180257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 28 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 135\n\n### Recent history (most recent last)\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 28, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 145, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.180257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 29 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 140\n\n### Recent history (most recent last)\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 29, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 150, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.180257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 30 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 145\n\n### Recent history (most recent last)\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 30, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 155, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.181257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 31 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 150\n\n### Recent history (most recent last)\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 31, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 160, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.181257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 32 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 155\n\n### Recent history (most recent last)\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 32, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 165, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.181257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 33 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 160\n\n### Recent history (most recent last)\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 33, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 170, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.182256+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 34 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 165\n\n### Recent history (most recent last)\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 34, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 175, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.182256+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 35 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 170\n\n### Recent history (most recent last)\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 35, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 180, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.182256+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 36 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 175\n\n### Recent history (most recent last)\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 36, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 185, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.183257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 37 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 180\n\n### Recent history (most recent last)\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 37, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 190, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.183257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 38 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 185\n\n### Recent history (most recent last)\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 38, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 195, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.183257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 39 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 190\n\n### Recent history (most recent last)\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 39, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 200, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.184257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 40 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 195\n\n### Recent history (most recent last)\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 40, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 205, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.184257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 41 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 200\n\n### Recent history (most recent last)\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 41, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 210, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.184257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 42 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 205\n\n### Recent history (most recent last)\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 42, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 215, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.184257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 43 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 210\n\n### Recent history (most recent last)\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 43, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 220, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.185257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 44 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 215\n\n### Recent history (most recent last)\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 44, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 225, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.185257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 45 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 220\n\n### Recent history (most recent last)\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 45, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 230, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.185257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 46 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 225\n\n### Recent history (most recent last)\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 46, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 235, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.186257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 47 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 230\n\n### Recent history (most recent last)\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 47, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 240, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.186257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 48 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 235\n\n### Recent history (most recent last)\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 48, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 245, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.186257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 49 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 240\n\n### Recent history (most recent last)\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 48: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 0, "round_index": 49, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 250, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.187257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 50 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 245\n\n### Recent history (most recent last)\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 48: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 49: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 0, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 5, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.189256+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 1 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 0\n\n### Recent history (most recent last)\nNo history yet (this is the first round).\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 1, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 10, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.189256+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 2 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 5\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 2, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.190257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 3 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 10\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 3, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 20, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.190257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 4 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 15\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 4, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 25, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.191257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 5 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 20\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 5, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.191257+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 6 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 25\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 6, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 35, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.192061+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 7 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 30\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 7, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 40, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.192061+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 8 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 35\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 8, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.192061+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 9 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 40\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 9, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 50, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.193067+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 10 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 45\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 10, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 55, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.193067+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 11 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 50\n\n### Recent history (most recent last)\nRound 1: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 11, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 60, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.193067+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 12 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 55\n\n### Recent history (most recent last)\nRound 2: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 12, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 65, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.194068+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 13 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 60\n\n### Recent history (most recent last)\nRound 3: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 13, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 70, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.194573+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 14 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 65\n\n### Recent history (most recent last)\nRound 4: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 14, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 75, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.194573+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 15 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 70\n\n### Recent history (most recent last)\nRound 5: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 15, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 80, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.194573+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 16 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 75\n\n### Recent history (most recent last)\nRound 6: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 16, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 85, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.195578+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 17 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 80\n\n### Recent history (most recent last)\nRound 7: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 17, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 90, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.195578+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 18 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 85\n\n### Recent history (most recent last)\nRound 8: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 18, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 95, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.195578+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 19 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 90\n\n### Recent history (most recent last)\nRound 9: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 19, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 100, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.196578+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 20 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 95\n\n### Recent history (most recent last)\nRound 10: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 20, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 105, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.196578+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 21 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 100\n\n### Recent history (most recent last)\nRound 11: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 21, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 110, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.196578+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 22 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 105\n\n### Recent history (most recent last)\nRound 12: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 22, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 115, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.197578+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 23 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 110\n\n### Recent history (most recent last)\nRound 13: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 23, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 120, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.197578+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 24 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 115\n\n### Recent history (most recent last)\nRound 14: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 24, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 125, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.197578+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 25 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 120\n\n### Recent history (most recent last)\nRound 15: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 25, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 130, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.198578+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 26 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 125\n\n### Recent history (most recent last)\nRound 16: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 26, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 135, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.198578+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 27 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 130\n\n### Recent history (most recent last)\nRound 17: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 27, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 140, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.198578+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 28 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 135\n\n### Recent history (most recent last)\nRound 18: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 28, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 145, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.198578+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 29 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 140\n\n### Recent history (most recent last)\nRound 19: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 29, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 150, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.198578+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 30 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 145\n\n### Recent history (most recent last)\nRound 20: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 30, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 155, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.200083+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 31 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 150\n\n### Recent history (most recent last)\nRound 21: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 31, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 160, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.200083+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 32 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 155\n\n### Recent history (most recent last)\nRound 22: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 32, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 165, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.200083+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 33 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 160\n\n### Recent history (most recent last)\nRound 23: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 33, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 170, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.201088+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 34 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 165\n\n### Recent history (most recent last)\nRound 24: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 34, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 175, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.201088+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 35 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 170\n\n### Recent history (most recent last)\nRound 25: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 35, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 180, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.201088+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 36 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 175\n\n### Recent history (most recent last)\nRound 26: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 36, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 185, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.202088+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 37 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 180\n\n### Recent history (most recent last)\nRound 27: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 37, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 190, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.202088+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 38 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 185\n\n### Recent history (most recent last)\nRound 28: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 38, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 195, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.202088+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 39 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 190\n\n### Recent history (most recent last)\nRound 29: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 39, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 200, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.203088+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 40 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 195\n\n### Recent history (most recent last)\nRound 30: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 40, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 205, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.203088+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 41 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 200\n\n### Recent history (most recent last)\nRound 31: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 41, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 210, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.203088+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 42 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 205\n\n### Recent history (most recent last)\nRound 32: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 42, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 215, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.203088+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 43 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 210\n\n### Recent history (most recent last)\nRound 33: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 43, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 220, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.204089+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 44 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 215\n\n### Recent history (most recent last)\nRound 34: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 44, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 225, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.204089+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 45 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 220\n\n### Recent history (most recent last)\nRound 35: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 45, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 230, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.204089+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 46 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 225\n\n### Recent history (most recent last)\nRound 36: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 46, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 235, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.205089+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 47 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 230\n\n### Recent history (most recent last)\nRound 37: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 47, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 240, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.205089+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 48 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 235\n\n### Recent history (most recent last)\nRound 38: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 48, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 245, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.205089+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 49 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 240\n\n### Recent history (most recent last)\nRound 39: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 48: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "MockLLM_cooperative_vs_ALLD", "replicate": 1, "round_index": 49, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 250, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.206089+00:00", "prompts": {"agent_a": {"system": "You are an agent playing the Iterated Prisoner's Dilemma (PD).\n\n## Rules\nEach round, you must choose exactly one action:\n- C = Cooperate\n- D = Defect\n\nYou will be shown:\n- The payoff table (your payoff and the other agent's payoff)\n- A short history of recent rounds\n- (Optionally) cumulative totals\n\n## Your objective\nMaximize your total payoff across the game, given the information you have.\n\n## Output format (STRICT)\nYou must output ONLY a single character: C or D.\nNo explanations, no extra text, no punctuation, no JSON.\n", "round": "Persona: Cooperative and constructive.\n\n- Start by cooperating (C).\n- Prefer mutual cooperation when it appears stable.\n- If the other agent defects, respond in a measured way to discourage exploitation.\n- Be willing to return to cooperation if the other agent cooperates again.\n\n\n### Payoff table\nYour action | Opponent action | Your payoff | Opponent payoff\n------------|-----------------|-------------|----------------\n     C      |        C        |      3      |       3\n     C      |        D        |      0      |       5\n     D      |        C        |      5      |       0\n     D      |        D        |      1      |       1\n\n### Current round\nRound 50 of 50\n\n### Cumulative totals\nYour cumulative payoff: 0\nOpponent's cumulative payoff: 245\n\n### Recent history (most recent last)\nRound 40: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 41: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 42: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 43: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 44: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 45: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 46: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 47: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 48: You played C, Opponent played D -> You got 0, Opponent got 5\nRound 49: You played C, Opponent played D -> You got 0, Opponent got 5\n\n### Choose your action\nRemember: output ONLY a single character: C or D.\n"}}, "raw_responses": {"agent_a": "C"}}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 0, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 5, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.207828+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 1, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 1, "agent_b_cum_payoff": 6, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.207828+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 2, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 2, "agent_b_cum_payoff": 7, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.207828+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 3, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 3, "agent_b_cum_payoff": 8, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.208834+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 4, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 4, "agent_b_cum_payoff": 9, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.208834+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 5, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 5, "agent_b_cum_payoff": 10, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.208834+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 6, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 6, "agent_b_cum_payoff": 11, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.208834+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 7, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 7, "agent_b_cum_payoff": 12, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.209833+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 8, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 8, "agent_b_cum_payoff": 13, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.209833+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 9, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 9, "agent_b_cum_payoff": 14, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.209833+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 10, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 10, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.209833+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 11, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 11, "agent_b_cum_payoff": 16, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.210834+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 12, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 12, "agent_b_cum_payoff": 17, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.210834+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 13, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 13, "agent_b_cum_payoff": 18, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.210834+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 14, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 14, "agent_b_cum_payoff": 19, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.211842+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 15, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 15, "agent_b_cum_payoff": 20, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.211842+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 16, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 16, "agent_b_cum_payoff": 21, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.211842+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 17, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 17, "agent_b_cum_payoff": 22, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.211842+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 18, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 18, "agent_b_cum_payoff": 23, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.212838+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 19, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 19, "agent_b_cum_payoff": 24, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.212838+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 20, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 20, "agent_b_cum_payoff": 25, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.212838+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 21, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 21, "agent_b_cum_payoff": 26, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.212838+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 22, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 22, "agent_b_cum_payoff": 27, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.213838+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 23, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 23, "agent_b_cum_payoff": 28, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.213838+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 24, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 24, "agent_b_cum_payoff": 29, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.213838+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 25, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 25, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.213838+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 26, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 26, "agent_b_cum_payoff": 31, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.214840+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 27, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 27, "agent_b_cum_payoff": 32, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.214840+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 28, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 28, "agent_b_cum_payoff": 33, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.214840+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 29, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 29, "agent_b_cum_payoff": 34, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.215838+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 30, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 30, "agent_b_cum_payoff": 35, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.215838+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 31, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 31, "agent_b_cum_payoff": 36, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.215838+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 32, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 32, "agent_b_cum_payoff": 37, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.215838+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 33, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 33, "agent_b_cum_payoff": 38, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.216838+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 34, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 34, "agent_b_cum_payoff": 39, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.216838+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 35, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 35, "agent_b_cum_payoff": 40, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.216838+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 36, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 36, "agent_b_cum_payoff": 41, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.216838+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 37, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 37, "agent_b_cum_payoff": 42, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.217841+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 38, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 38, "agent_b_cum_payoff": 43, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.217841+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 39, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 39, "agent_b_cum_payoff": 44, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.217841+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 40, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 40, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.217841+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 41, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 41, "agent_b_cum_payoff": 46, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.218841+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 42, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 42, "agent_b_cum_payoff": 47, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.218841+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 43, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 43, "agent_b_cum_payoff": 48, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.218841+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 44, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 44, "agent_b_cum_payoff": 49, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.218841+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 45, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 45, "agent_b_cum_payoff": 50, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.219840+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 46, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 46, "agent_b_cum_payoff": 51, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.219840+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 47, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 47, "agent_b_cum_payoff": 52, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.219840+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 48, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 48, "agent_b_cum_payoff": 53, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.220839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 0, "round_index": 49, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 49, "agent_b_cum_payoff": 54, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.220839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 0, "agent_a_action": "C", "agent_b_action": "D", "agent_a_payoff": 0, "agent_b_payoff": 5, "agent_a_cum_payoff": 0, "agent_b_cum_payoff": 5, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.221839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 1, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 1, "agent_b_cum_payoff": 6, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.221839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 2, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 2, "agent_b_cum_payoff": 7, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.222839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 3, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 3, "agent_b_cum_payoff": 8, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.222839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 4, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 4, "agent_b_cum_payoff": 9, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.222839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 5, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 5, "agent_b_cum_payoff": 10, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.223839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 6, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 6, "agent_b_cum_payoff": 11, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.223839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 7, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 7, "agent_b_cum_payoff": 12, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.223839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 8, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 8, "agent_b_cum_payoff": 13, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.223839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 9, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 9, "agent_b_cum_payoff": 14, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.224839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 10, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 10, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.224839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 11, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 11, "agent_b_cum_payoff": 16, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.224839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 12, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 12, "agent_b_cum_payoff": 17, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.225839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 13, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 13, "agent_b_cum_payoff": 18, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.225839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 14, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 14, "agent_b_cum_payoff": 19, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.225839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 15, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 15, "agent_b_cum_payoff": 20, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.225839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 16, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 16, "agent_b_cum_payoff": 21, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.226839+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 17, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 17, "agent_b_cum_payoff": 22, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.227344+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 18, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 18, "agent_b_cum_payoff": 23, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.227344+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 19, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 19, "agent_b_cum_payoff": 24, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.227344+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 20, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 20, "agent_b_cum_payoff": 25, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.227344+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 21, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 21, "agent_b_cum_payoff": 26, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.228349+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 22, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 22, "agent_b_cum_payoff": 27, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.228349+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 23, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 23, "agent_b_cum_payoff": 28, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.229353+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 24, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 24, "agent_b_cum_payoff": 29, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.229353+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 25, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 25, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.229353+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 26, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 26, "agent_b_cum_payoff": 31, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.230350+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 27, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 27, "agent_b_cum_payoff": 32, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.230350+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 28, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 28, "agent_b_cum_payoff": 33, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.230350+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 29, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 29, "agent_b_cum_payoff": 34, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.231350+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 30, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 30, "agent_b_cum_payoff": 35, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.231350+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 31, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 31, "agent_b_cum_payoff": 36, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.231350+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 32, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 32, "agent_b_cum_payoff": 37, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.231350+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 33, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 33, "agent_b_cum_payoff": 38, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.232350+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 34, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 34, "agent_b_cum_payoff": 39, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.232350+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 35, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 35, "agent_b_cum_payoff": 40, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.232350+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 36, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 36, "agent_b_cum_payoff": 41, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.233350+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 37, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 37, "agent_b_cum_payoff": 42, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.233350+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 38, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 38, "agent_b_cum_payoff": 43, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.233350+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 39, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 39, "agent_b_cum_payoff": 44, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.234349+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 40, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 40, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.234349+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 41, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 41, "agent_b_cum_payoff": 46, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.234349+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 42, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 42, "agent_b_cum_payoff": 47, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.234349+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 43, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 43, "agent_b_cum_payoff": 48, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.235354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 44, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 44, "agent_b_cum_payoff": 49, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.235354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 45, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 45, "agent_b_cum_payoff": 50, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.235354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 46, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 46, "agent_b_cum_payoff": 51, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.236355+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 47, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 47, "agent_b_cum_payoff": 52, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.236355+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 48, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 48, "agent_b_cum_payoff": 53, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.236355+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_ALLD", "replicate": 1, "round_index": 49, "agent_a_action": "D", "agent_b_action": "D", "agent_a_payoff": 1, "agent_b_payoff": 1, "agent_a_cum_payoff": 49, "agent_b_cum_payoff": 54, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.237354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 0, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 3, "agent_b_cum_payoff": 3, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.238359+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 1, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 6, "agent_b_cum_payoff": 6, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.239355+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 2, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 9, "agent_b_cum_payoff": 9, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.239355+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 3, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 12, "agent_b_cum_payoff": 12, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.239355+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 4, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 15, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.240355+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 5, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 18, "agent_b_cum_payoff": 18, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.240355+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 6, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 21, "agent_b_cum_payoff": 21, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.240355+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 7, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 24, "agent_b_cum_payoff": 24, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.240355+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 8, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 27, "agent_b_cum_payoff": 27, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.241357+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 9, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 30, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.241357+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 10, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 33, "agent_b_cum_payoff": 33, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.241357+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 11, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 36, "agent_b_cum_payoff": 36, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.242354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 12, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 39, "agent_b_cum_payoff": 39, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.242354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 13, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 42, "agent_b_cum_payoff": 42, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.242354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 14, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 45, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.242354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 15, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 48, "agent_b_cum_payoff": 48, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.243354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 16, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 51, "agent_b_cum_payoff": 51, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.243354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 17, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 54, "agent_b_cum_payoff": 54, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.243354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 18, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 57, "agent_b_cum_payoff": 57, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.243354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 19, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 60, "agent_b_cum_payoff": 60, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.244354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 20, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 63, "agent_b_cum_payoff": 63, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.244354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 21, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 66, "agent_b_cum_payoff": 66, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.244354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 22, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 69, "agent_b_cum_payoff": 69, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.245354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 23, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 72, "agent_b_cum_payoff": 72, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.245354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 24, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 75, "agent_b_cum_payoff": 75, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.245354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 25, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 78, "agent_b_cum_payoff": 78, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.245354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 26, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 81, "agent_b_cum_payoff": 81, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.246354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 27, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 84, "agent_b_cum_payoff": 84, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.246354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 28, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 87, "agent_b_cum_payoff": 87, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.246354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 29, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 90, "agent_b_cum_payoff": 90, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.246354+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 30, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 93, "agent_b_cum_payoff": 93, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.247357+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 31, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 96, "agent_b_cum_payoff": 96, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.247357+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 32, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 99, "agent_b_cum_payoff": 99, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.247357+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 33, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 102, "agent_b_cum_payoff": 102, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.248355+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 34, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 105, "agent_b_cum_payoff": 105, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.248355+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 35, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 108, "agent_b_cum_payoff": 108, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.248355+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 36, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 111, "agent_b_cum_payoff": 111, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.248355+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 37, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 114, "agent_b_cum_payoff": 114, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.248355+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 38, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 117, "agent_b_cum_payoff": 117, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.248355+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 39, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 120, "agent_b_cum_payoff": 120, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.249859+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 40, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 123, "agent_b_cum_payoff": 123, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.249859+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 41, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 126, "agent_b_cum_payoff": 126, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.249859+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 42, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 129, "agent_b_cum_payoff": 129, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.250864+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 43, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 132, "agent_b_cum_payoff": 132, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.250864+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 44, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 135, "agent_b_cum_payoff": 135, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.250864+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 45, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 138, "agent_b_cum_payoff": 138, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.250864+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 46, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 141, "agent_b_cum_payoff": 141, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.251864+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 47, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 144, "agent_b_cum_payoff": 144, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.251864+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 48, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 147, "agent_b_cum_payoff": 147, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.251864+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 0, "round_index": 49, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 150, "agent_b_cum_payoff": 150, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.251864+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 0, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 3, "agent_b_cum_payoff": 3, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.253423+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 1, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 6, "agent_b_cum_payoff": 6, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.254430+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 2, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 9, "agent_b_cum_payoff": 9, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.254430+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 3, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 12, "agent_b_cum_payoff": 12, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.254430+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 4, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 15, "agent_b_cum_payoff": 15, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.254430+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 5, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 18, "agent_b_cum_payoff": 18, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.254430+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 6, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 21, "agent_b_cum_payoff": 21, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.255934+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 7, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 24, "agent_b_cum_payoff": 24, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.255934+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 8, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 27, "agent_b_cum_payoff": 27, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.255934+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 9, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 30, "agent_b_cum_payoff": 30, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.256939+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 10, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 33, "agent_b_cum_payoff": 33, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.256939+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 11, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 36, "agent_b_cum_payoff": 36, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.256939+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 12, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 39, "agent_b_cum_payoff": 39, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.256939+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 13, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 42, "agent_b_cum_payoff": 42, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.257940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 14, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 45, "agent_b_cum_payoff": 45, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.257940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 15, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 48, "agent_b_cum_payoff": 48, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.257940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 16, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 51, "agent_b_cum_payoff": 51, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.257940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 17, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 54, "agent_b_cum_payoff": 54, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.258940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 18, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 57, "agent_b_cum_payoff": 57, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.258940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 19, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 60, "agent_b_cum_payoff": 60, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.258940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 20, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 63, "agent_b_cum_payoff": 63, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.258940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 21, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 66, "agent_b_cum_payoff": 66, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.259940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 22, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 69, "agent_b_cum_payoff": 69, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.259940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 23, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 72, "agent_b_cum_payoff": 72, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.259940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 24, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 75, "agent_b_cum_payoff": 75, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.260940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 25, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 78, "agent_b_cum_payoff": 78, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.260940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 26, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 81, "agent_b_cum_payoff": 81, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.260940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 27, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 84, "agent_b_cum_payoff": 84, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.260940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 28, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 87, "agent_b_cum_payoff": 87, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.261940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 29, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 90, "agent_b_cum_payoff": 90, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.261940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 30, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 93, "agent_b_cum_payoff": 93, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.261940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 31, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 96, "agent_b_cum_payoff": 96, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.261940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 32, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 99, "agent_b_cum_payoff": 99, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.262940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 33, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 102, "agent_b_cum_payoff": 102, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.262940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 34, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 105, "agent_b_cum_payoff": 105, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.262940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 35, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 108, "agent_b_cum_payoff": 108, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.262940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 36, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 111, "agent_b_cum_payoff": 111, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.263940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 37, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 114, "agent_b_cum_payoff": 114, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.263940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 38, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 117, "agent_b_cum_payoff": 117, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.263940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 39, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 120, "agent_b_cum_payoff": 120, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.263940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 40, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 123, "agent_b_cum_payoff": 123, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.264940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 41, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 126, "agent_b_cum_payoff": 126, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.264940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 42, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 129, "agent_b_cum_payoff": 129, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.264940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 43, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 132, "agent_b_cum_payoff": 132, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.265941+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 44, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 135, "agent_b_cum_payoff": 135, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.265941+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 45, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 138, "agent_b_cum_payoff": 138, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.265941+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 46, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 141, "agent_b_cum_payoff": 141, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.265941+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 47, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 144, "agent_b_cum_payoff": 144, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.266940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 48, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 147, "agent_b_cum_payoff": 147, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.266940+00:00"}
{"run_id": "phase1_smoke_v1", "condition": "TFT_vs_WSLS", "replicate": 1, "round_index": 49, "agent_a_action": "C", "agent_b_action": "C", "agent_a_payoff": 3, "agent_b_payoff": 3, "agent_a_cum_payoff": 150, "agent_b_cum_payoff": 150, "horizon_type": "fixed", "fixed_n": 50, "stop_prob": null, "timestamp_utc": "2026-01-27T21:30:28.266940+00:00"}
